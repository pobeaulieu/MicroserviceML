{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Type-based Service Identification (Grouping by Same Type Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v_imen\" # All options: v_imen, v_team\n",
    "system = \"pos\" # All options: jforum, cargotracker, petclinic, pos\n",
    "# Pas d'influence du mod√®le d'embeddings puisqu'on n'utilise que les distances statiques\n",
    "model_type = \"codebert\" # All options: ft_codebert, word2vec, albert, codebert, roberta, bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create class graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_communities, save_communities_to_csv, load_class_data, load_call_graph, merge_dataframes\n",
    "from distances import compute_semantic_distances_for_class_pairs\n",
    "from visualization import visualize_class_distance_heatmap\n",
    "from normalization import filter_and_normalize_distances\n",
    "from community_tuning import fine_tune_all_services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "_, class_labels_dict, class_embeddings_dict = load_class_data(system, version, model_type)\n",
    "static_df = load_call_graph(system)\n",
    "\n",
    "if system == 'cargotracker': # temporary fix\n",
    "    # Replace 'org.eclipse' with 'net.java' in both class1 and class2 columns\n",
    "    static_df['class1'] = static_df['class1'].str.replace('org.eclipse', 'net.java', regex=False)\n",
    "    static_df['class2'] = static_df['class2'].str.replace('org.eclipse', 'net.java', regex=False)\n",
    "\n",
    "semantic_df = compute_semantic_distances_for_class_pairs(class_embeddings_dict)\n",
    "static_df = filter_and_normalize_distances(static_df, class_labels_dict)\n",
    "semantic_df = filter_and_normalize_distances(semantic_df, class_labels_dict)\n",
    "class_graph = merge_dataframes(static_df, semantic_df)\n",
    "\n",
    "# Visualizations\n",
    "visualize_class_distance_heatmap(class_graph, 'static_distance', \"Static Distances Between Classes\")\n",
    "visualize_class_distance_heatmap(class_graph, 'semantic_distance', \"Semantic Distances Between Classes\")\n",
    "\n",
    "# Save to CSV\n",
    "filename = f\"./generated_data/graph/class/{version}_{system}_class_graph.csv\"\n",
    "class_graph.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from community_detection import CommunityDetection\n",
    "from constants import COMMUNITY_DETECTION_ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "G = nx.from_pandas_edgelist(class_graph[class_graph['static_distance'] != 0], 'class1', 'class2', ['static_distance'])\n",
    "cd = CommunityDetection(G, class_labels_dict, optimize_hyperparameters_flag=False)  # Set optimize_hyperparameters_flag=True if you wish optimize parameters of clustering algorithms\n",
    "\n",
    "# Fine-tuning clusters using static distance\n",
    "distances = [(row['class1'], row['class2'], row['static_distance']) for index, row in class_graph.iterrows()]  # OR other distances\n",
    "\n",
    "for algorithm in COMMUNITY_DETECTION_ALGORITHMS: # OR use those you need\n",
    "    print(f\"Running {algorithm} algorithm...\")\n",
    "    \n",
    "    communities = {\n",
    "        'Application': cd.detect_communities('Application', algorithm),\n",
    "        'Entity': cd.detect_communities('Entity', algorithm),\n",
    "        'Utility': cd.detect_communities('Utility', algorithm)\n",
    "    }\n",
    "\n",
    "    fine_tuned_communities = {\n",
    "        label_type: fine_tune_all_services(services, distances)\n",
    "        for label_type, services in communities.items()\n",
    "    }\n",
    "\n",
    "    # Print the communities\n",
    "    for label_type, services in fine_tuned_communities.items():\n",
    "        print_communities(label_type, services)\n",
    "\n",
    "    # Save fine-tuned communities to CSV\n",
    "    save_communities_to_csv(fine_tuned_communities, version, system, algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Measures (F-Measure, Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_helpers import generate_services_clustering_results\n",
    "\n",
    "models = ['custom_cmeans', 'cmeans', 'hierarchical']\n",
    "\n",
    "matching_threshold = 0.8\n",
    "\n",
    "generate_microservices_clustering_results_by_model(models, version, system, best_community_detection_algorithm, matching_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Classification (assign Utility, Application, or Entity Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v_imen\" # All options: v_imen, v_team\n",
    "system = \"pos\" # All options: jforum, cargotracker, petclinic, pos\n",
    "model_type = \"albert\" # All options: ft_codebert, word2vec, albert, codebert, roberta, bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AlbertTokenizer, AlbertModel, RobertaModel, RobertaTokenizer, BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from utils import load_class_code_from_directory, load_data_from_csv, write_embeddings_to_csv, associate_classes_to_types, write_distance_to_csv\n",
    "from embeddings import generate_embeddings_for_java_code, generate_word_embeddings_for_java_code\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU) is available and if so, set the device to GPU\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and tokenizer\n",
    "if (model_type == \"codebert\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\",force_download=False)\n",
    "    model = AutoModel.from_pretrained(\"microsoft/codebert-base\",force_download=False)\n",
    "elif (model_type == \"ft_codebert\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./codebert_finetuned\",force_download=False)\n",
    "    model = AutoModel.from_pretrained(\"./codebert_finetuned\",force_download=False)\n",
    "elif (model_type == \"bert\"):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") \n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\") \n",
    "elif (model_type == \"roberta\"):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "elif (model_type == \"albert\"): \n",
    "    # pip3 install sentencepiece\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "    model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "elif model_type == \"word2vec\":\n",
    "    # Download required NLTK datasets and initialize the lemmatizer\n",
    "    nltk.download('wordnet')\n",
    "    word_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Load Word2Vec model\n",
    "    word2vec_model = api.load('word2vec-google-news-300')\n",
    "else:\n",
    "    raise NameError(\"model type not supported\")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are 0: Application, 1: Utility, 2: Entity\n",
    "class_labels = associate_classes_to_types(version, system)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each class in class_code, generate embeddings and add to class_embeddings dictionary\n",
    "class_embeddings = {}\n",
    "class_code = load_class_code_from_directory(system)\n",
    "if model_type == \"word2vec\":\n",
    "    class_embeddings = {class_name: generate_word_embeddings_for_java_code(code, model, word_lemmatizer) for class_name, code in class_code.items()}\n",
    "else:\n",
    "    class_embeddings = {class_name: generate_embeddings_for_java_code(code, model, tokenizer, device) for class_name, code in class_code.items()}\n",
    "\n",
    "# Write embeddings to csv file\n",
    "write_embeddings_to_csv(version, system, model_type, class_embeddings, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "filename = f\"./csv_files/{version}_{system}_{model_type}_embeddings.csv\"\n",
    "class_names, labels, embeddings = load_data_from_csv(filename)\n",
    "\n",
    "# Train-test split\n",
    "Xtrain, Xtest, names_train, names_test = train_test_split(embeddings, class_names, test_size=0.3, random_state=0)\n",
    "\n",
    "# Get labels for the training and test sets\n",
    "ytrain, ytest = [[labels[class_names.index(name)] for name in lst] for lst in [names_train, names_test]]\n",
    "\n",
    "# Ensure at least one instance of each class in the training data\n",
    "unique_classes = set(labels)\n",
    "for cls in unique_classes:\n",
    "    if cls not in ytrain:\n",
    "        cls_index = labels.index(cls)\n",
    "        Xtrain = np.vstack([Xtrain, [embeddings[cls_index]]])\n",
    "        ytrain.append(cls)\n",
    "\n",
    "# Calculate class frequencies and mean frequency\n",
    "class_freq = Counter(ytrain)\n",
    "mean_count = sum(class_freq.values()) // len(class_freq)\n",
    "\n",
    "# Identify classes that need resampling (e.g., significantly fewer than mean_count)\n",
    "threshold = 0.7  # 70% of the mean_count\n",
    "classes_to_resample = {cls: int(mean_count) for cls, count in class_freq.items() if count < mean_count * threshold}\n",
    "\n",
    "# Check if all classes_to_resample have enough samples\n",
    "skip_resampling = False\n",
    "for class_label in classes_to_resample.keys():\n",
    "    if class_label in class_freq and class_freq[class_label] < 2:  # k_neighbors + 1\n",
    "        skip_resampling = True\n",
    "        print(f\"Skipping resampling for class {class_label} due to insufficient samples.\")\n",
    "        break\n",
    "\n",
    "# Apply SMOTE\n",
    "if not skip_resampling and classes_to_resample:\n",
    "    sm = SMOTE(sampling_strategy=classes_to_resample, k_neighbors=1, random_state=42)\n",
    "    Xtrain, ytrain = sm.fit_resample(Xtrain, ytrain)\n",
    "\n",
    "# Print information\n",
    "print(f'Number of classes: {len(class_names)}\\nResampled dataset shape: {Counter(ytrain)}')\n",
    "print(f'len(Xtrain): {len(Xtrain)}\\nlen(Xtest): {len(Xtest)}')\n",
    "print(f'ytrain: {ytrain}\\nytest: {ytest}')\n",
    "print(f'ytrain count: {np.bincount(ytrain)}\\nytest count: {np.bincount(ytest)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OPTIONAL: Please keep this code commented out unless you want to use it\n",
    "# # This code ensures that each class is represented in the test set, proportional to its representation in the training set\n",
    "# # Calculate class frequencies for training and test sets\n",
    "# train_class_freq = Counter(ytrain)\n",
    "# test_class_freq = Counter(ytest)\n",
    "\n",
    "# # Calculate the ratio between the size of the training and test sets\n",
    "# ratio = len(ytrain) / len(ytest)\n",
    "\n",
    "# # Iterate over each class to make sure it has proportional representation in the test set\n",
    "# for cls, train_count in train_class_freq.items():\n",
    "#     expected_test_count = int(train_count / ratio)\n",
    "#     actual_test_count = test_class_freq.get(cls, 0)\n",
    "\n",
    "#     if actual_test_count < expected_test_count:\n",
    "#         # Find instances in the training set to move to the test set\n",
    "#         for _ in range(expected_test_count - actual_test_count):\n",
    "#             cls_index = ytrain.index(cls)\n",
    "#             Xtest = np.vstack([Xtest, [Xtrain[cls_index]]])\n",
    "#             ytest.append(cls)\n",
    "#             Xtrain = np.delete(Xtrain, cls_index, axis=0)\n",
    "#             ytrain.pop(cls_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_report(y_true, y_pred):\n",
    "    # Identify unique labels in both true labels and predictions\n",
    "    unique_labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "\n",
    "    # Map unique labels to their corresponding names\n",
    "    label_names_map = {-1: \"None\", 0: \"Application\", 1: \"Utility\", 2: \"Entity\"}\n",
    "    dynamic_label_names = [label_names_map[label] for label in unique_labels]\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=dynamic_label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=2).fit(Xtrain, ytrain)\n",
    "decision_tree_predictions = decision_tree_classifier.predict(Xtest)\n",
    "decision_tree_accuracy = accuracy_score(ytest, decision_tree_predictions)\n",
    "decision_tree_confusion_matrix = confusion_matrix(ytest, decision_tree_predictions)\n",
    "print(decision_tree_accuracy)\n",
    "print(decision_tree_confusion_matrix)\n",
    "generate_classification_report(ytest, decision_tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=2, probability=True).fit(Xtrain, ytrain)\n",
    "svm_predictions = svm_classifier.predict(Xtest)\n",
    "svm_accuracy = accuracy_score(ytest, svm_predictions)\n",
    "svm_confusion_matrix = confusion_matrix(ytest, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "print(svm_confusion_matrix)\n",
    "generate_classification_report(ytest, svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=5).fit(Xtrain, ytrain)\n",
    "knn_predictions = knn_classifier.predict(Xtest)\n",
    "knn_accuracy = accuracy_score(ytest, knn_predictions)\n",
    "knn_confusion_matrix = confusion_matrix(ytest, knn_predictions)\n",
    "print(knn_accuracy)\n",
    "print(knn_confusion_matrix)\n",
    "generate_classification_report(ytest, knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_classifier = LogisticRegression(random_state=0).fit(Xtrain, ytrain)\n",
    "logistic_regression_predictions = logistic_regression_classifier.predict(Xtest)\n",
    "logistic_regression_accuracy = accuracy_score(ytest, logistic_regression_predictions)\n",
    "logistic_regression_confusion_matrix = confusion_matrix(ytest, logistic_regression_predictions)\n",
    "print(logistic_regression_accuracy)\n",
    "print(logistic_regression_confusion_matrix)\n",
    "generate_classification_report(ytest, logistic_regression_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = GaussianNB().fit(Xtrain, ytrain)\n",
    "naive_bayes_predictions = naive_bayes_classifier.predict(Xtest)\n",
    "naive_bayes_accuracy = accuracy_score(ytest, naive_bayes_predictions)\n",
    "naive_bayes_confusion_matrix = confusion_matrix(ytest, naive_bayes_predictions)\n",
    "print(naive_bayes_accuracy)\n",
    "print(naive_bayes_confusion_matrix)\n",
    "generate_classification_report(ytest, naive_bayes_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine individual classifiers into an ensemble\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "('svm', svm_classifier), ('knn', knn_classifier), ('dt', decision_tree_classifier), ('log_reg', logistic_regression_classifier), ('gnb', naive_bayes_classifier)],\n",
    "voting='soft')\n",
    "\n",
    "# Use SVM as the base estimator for AdaBoost\n",
    "svm_base = SVC(kernel='linear', C=2, probability=True) # Can use any other classifier as the base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=svm_base, n_estimators=50, algorithm='SAMME.R', random_state=1)\n",
    "\n",
    "# Combine the ensemble classifier with AdaBoost\n",
    "final_ensemble = VotingClassifier(estimators=[\n",
    "    ('ensemble_clf', ensemble_clf), ('ada_boost', ada_boost)],\n",
    "    voting='soft')\n",
    "\n",
    "# Fit model to your data\n",
    "final_ensemble.fit(Xtrain, ytrain)\n",
    "\n",
    "# Evaluate model\n",
    "ensemble_predictions = final_ensemble.predict(Xtest)\n",
    "ensemble_accuracy = accuracy_score(ytest, ensemble_predictions)\n",
    "print('Accuracy:', ensemble_accuracy)\n",
    "ensemble_confusion_matrix = confusion_matrix(ytest, ensemble_predictions)\n",
    "print(ensemble_confusion_matrix)\n",
    "print(classification_report(ytest, ensemble_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

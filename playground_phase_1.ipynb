{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Classification (assign Utility, Application, or Entity Tag)\n",
    "\n",
    "## 1.1 Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v_team\" # TODO changer\n",
    "system = \"pos\" # TODO changer\n",
    "model_type = \"albert\" # or ft_codebert, word2vec, albert, codebert, roberta, bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AlbertTokenizer, AlbertModel, RobertaModel, RobertaTokenizer, BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import load_class_code_from_directory, load_data_from_csv, save_embeddings_to_csv, associate_classes_to_types\n",
    "from embeddings import generate_embeddings_for_java_code, generate_word_embeddings_for_java_code\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec # not used\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU) is available and if so, set the device to GPU\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and tokenizer\n",
    "if (model_type == \"codebert\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\",force_download=False)\n",
    "    model = AutoModel.from_pretrained(\"microsoft/codebert-base\",force_download=False)\n",
    "elif (model_type == \"ft_codebert\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./codebert_finetuned\",force_download=False)\n",
    "    model = AutoModel.from_pretrained(\"./codebert_finetuned\",force_download=False)\n",
    "elif (model_type == \"bert\"):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") \n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\") \n",
    "elif (model_type == \"roberta\"):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "elif (model_type == \"albert\"): \n",
    "    # pip3 install sentencepiece\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "    model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "elif model_type == \"word2vec\":\n",
    "    # Download required NLTK datasets and initialize the lemmatizer\n",
    "    nltk.download('wordnet')\n",
    "    word_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Load Word2Vec model\n",
    "    word2vec_model = api.load('word2vec-google-news-300')\n",
    "else:\n",
    "    raise NameError(\"model type not supported\")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are 0: Application, 1: Utility, 2: Entity\n",
    "class_labels = associate_classes_to_types(version, system)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each class in class_code, generate embeddings and add to class_embeddings dictionary\n",
    "class_embeddings = {}\n",
    "class_code = load_class_code_from_directory(system)\n",
    "if model_type == \"word2vec\":\n",
    "    class_embeddings = {class_name: generate_word_embeddings_for_java_code(code) for class_name, code in class_code.items()}\n",
    "else:\n",
    "    class_embeddings = {class_name: generate_embeddings_for_java_code(code, tokenizer, model, device) for class_name, code in class_code.items()}\n",
    "\n",
    "# Write embeddings to csv file\n",
    "save_embeddings_to_csv(version, system, model_type, class_embeddings, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{version}_{system}_{model_type}_embeddings.csv\"\n",
    "class_names, labels, embeddings = load_data_from_csv(filename)\n",
    "\n",
    "Xtrain, Xtest, names_train, names_test = train_test_split(embeddings, class_names, test_size=0.3, random_state=0)\n",
    "\n",
    "ytrain = [labels[class_names.index(name)] for name in names_train]\n",
    "ytest = [labels[class_names.index(name)] for name in names_test]\n",
    "\n",
    "Xtrain = np.array(Xtrain)\n",
    "Xtest = np.array(Xtest)\n",
    "\n",
    "# Ensure that there's at least one instance of the \"Utility\" label in the training data\n",
    "if 1 not in ytrain:\n",
    "    utility_index = labels.index(1)\n",
    "    Xtrain = np.append(Xtrain, [embeddings[utility_index]], axis=0)\n",
    "    ytrain.append(1)\n",
    "\n",
    "print(Xtrain)\n",
    "print(len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_report(y_true, y_pred):\n",
    "    # Identify unique labels in both true labels and predictions\n",
    "    unique_labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "\n",
    "    # Map unique labels to their corresponding names\n",
    "    label_names_map = {-1: \"None\", 0: \"Application\", 1: \"Utility\", 2: \"Entity\"}\n",
    "    dynamic_label_names = [label_names_map[label] for label in unique_labels]\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=dynamic_label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=2).fit(Xtrain, ytrain)\n",
    "decision_tree_predictions = decision_tree_classifier.predict(Xtest)\n",
    "decision_tree_accuracy = accuracy_score(ytest, decision_tree_predictions)\n",
    "decision_tree_confusion_matrix = confusion_matrix(ytest, decision_tree_predictions)\n",
    "print(decision_tree_accuracy)\n",
    "print(decision_tree_confusion_matrix)\n",
    "generate_classification_report(ytest, decision_tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=2).fit(Xtrain, ytrain)\n",
    "svm_predictions = svm_classifier.predict(Xtest)\n",
    "svm_accuracy = accuracy_score(ytest, svm_predictions)\n",
    "svm_confusion_matrix = confusion_matrix(ytest, svm_predictions)\n",
    "print(svm_accuracy)\n",
    "print(svm_confusion_matrix)\n",
    "generate_classification_report(ytest, svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=5).fit(Xtrain, ytrain)\n",
    "knn_predictions = knn_classifier.predict(Xtest)\n",
    "knn_accuracy = accuracy_score(ytest, knn_predictions)\n",
    "knn_confusion_matrix = confusion_matrix(ytest, knn_predictions)\n",
    "print(knn_accuracy)\n",
    "print(knn_confusion_matrix)\n",
    "generate_classification_report(ytest, knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_classifier = LogisticRegression(random_state=0).fit(Xtrain, ytrain)\n",
    "logistic_regression_predictions = logistic_regression_classifier.predict(Xtest)\n",
    "logistic_regression_accuracy = accuracy_score(ytest, logistic_regression_predictions)\n",
    "logistic_regression_confusion_matrix = confusion_matrix(ytest, logistic_regression_predictions)\n",
    "print(logistic_regression_accuracy)\n",
    "print(logistic_regression_confusion_matrix)\n",
    "generate_classification_report(ytest, logistic_regression_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = GaussianNB().fit(Xtrain, ytrain)\n",
    "naive_bayes_predictions = naive_bayes_classifier.predict(Xtest)\n",
    "naive_bayes_accuracy = accuracy_score(ytest, naive_bayes_predictions)\n",
    "naive_bayes_confusion_matrix = confusion_matrix(ytest, naive_bayes_predictions)\n",
    "print(naive_bayes_accuracy)\n",
    "print(naive_bayes_confusion_matrix)\n",
    "generate_classification_report(ytest, naive_bayes_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
